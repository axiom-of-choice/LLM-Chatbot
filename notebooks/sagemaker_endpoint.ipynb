{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "import sys \n",
    "sys.path.append(os.path.abspath(os.path.join('../')))\n",
    "from langchain import LLMChain\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "import os\n",
    "import json\n",
    "\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from config import *\n",
    "from src.utils import connect_index\n",
    "\n",
    "region = os.environ[\"AWS_REGION\"]\n",
    "endpoint_name = os.environ[\"FALCON_ENDPOINT_NAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = CohereEmbeddings(model=COHERE_MODEL_NAME, cohere_api_key=COHERE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = connect_index(PINECONE_INDEX_NAME)\n",
    "vectorstore = Pinecone(index, embeddings.embed_query, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": prompt,\n",
    "        \"parameters\" : {**model_kwargs}})\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"{content}\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 13:47:31.864 Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "content_handler = ContentHandler()\n",
    "\n",
    "llm=SagemakerEndpoint(\n",
    "     endpoint_name=endpoint_name, \n",
    "     region_name=region, \n",
    "     model_kwargs={\"max_new_tokens\": 500, \"top_p\": 0.9, \"max_length\": None, \"temperature\":0.01},\n",
    "     endpoint_kwargs={\"CustomAttributes\": 'accept_eula=true'},\n",
    "     content_handler=content_handler,\n",
    "     credentials_profile_name=\"fundamentl-ai\"\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQAWithSourcesChain.from_chain_type(llm=llm, retriever=vectorstore.as_retriever(), chain_type=\"refine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is Semantich  Search?\"\n",
    "# Send question as a query to qa chain\n",
    "result = qa({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is Semantich  Search?',\n",
       " 'answer': '\\nThe original answer is correct, but it may not be sufficient for the question. The question asks about the search engine Semantich Search, and the answer is about the STSG algorithm. To answer the question, we need to provide more information about Semantich Search.\\n\\nSemantich Search is a search engine that uses probabilistic principles to search for information in a corpus. It is designed to be able to handle large amounts of data and to be able to provide accurate results in a timely manner. The search engine is designed to be able to handle both P and NP-complete problems, although this is yet unproven. The search engine is designed to be able to handle large amounts of data and to be able to provide accurate results in a timely manner.\\n\\nThe STSG algorithm is a parsing algorithm that is used to parse a grammar. It is designed to be able to parse a grammar that is defined in a specific language. The STSG algorithm is designed to be able to parse a grammar that is defined in a specific language. It is designed to be able to parse a grammar that is defined in a specific language.\\n\\nThe STSG algorithm is designed to be able to parse a grammar that is defined in a specific language. It is designed to be able to parse a grammar that is defined in a specific language. It is designed to be able to parse a grammar that is defined in a specific language.\\n\\nThe STSG algorithm is designed to be able to parse a grammar that is defined in a specific language. It is designed to be able to parse a grammar that is defined in a specific language. It is designed to be able to parse a grammar that is defined in a specific language.\\n\\nThe STSG algorithm is designed to be able to parse a grammar that is defined in a specific language. It is designed to be able to parse a grammar that is defined in a specific language. It is designed to be able to parse a grammar that is defined in a specific language.\\n\\nThe STSG algorithm is designed to be able to parse a grammar that is defined in a specific language. It is designed to be able to parse a grammar that is defined in a specific language. It is designed to be able to parse a grammar that is defined in a specific language.\\n\\nThe STSG algorithm is designed to be able to parse a grammar that is defined in a specific language. It is designed to be able to parse a grammar',\n",
       " 'sources': ''}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is STSG algorithm?\"\n",
    "# Send question as a query to qa chain\n",
    "result = qa({\"question\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is STSG algorithm?',\n",
       " 'answer': '\\nThe STSG algorithm is a search algorithm used in artificial intelligence to find the best solution to a problem. It is commonly used in optimization problems, such as finding the best route in a graph or the best solution to a puzzle. The algorithm uses a greedy approach to search for the best solution, where it always tries to maximize its current state. In the context of the question, the dog with no nose is the best solution, as it is the most efficient and optimal solution.',\n",
       " 'sources': ''}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "     llm=llm,\n",
    "     prompt=prompt\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThere are several ways to travel from New York to Los Angeles. One option is to take a flight, which can be booked through various airlines. Another option is to take a train, such as Amtrak's California Zephyr, which departs from New York and stops in Los Angeles. You can also take a bus or drive, but these options may take longer and require more planning.\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run({\"How can I travel from New York to Los Angeles?\"})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
