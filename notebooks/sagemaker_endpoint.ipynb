{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface-pytorch-tgi-inference-2023-08-09-22-11-09-254\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "\n",
    "import sys \n",
    "sys.path.append(os.path.abspath(os.path.join('../')))\n",
    "from langchain import LLMChain\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "import os\n",
    "import json\n",
    "\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from config import *\n",
    "from src.utils import connect_index\n",
    "\n",
    "region = os.environ[\"AWS_REGION\"]\n",
    "endpoint_name = os.environ[\"SAGEMAKER_ENDPOINT_NAME\"]\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = CohereEmbeddings(model=COHERE_MODEL_NAME, cohere_api_key=COHERE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = connect_index(PINECONE_INDEX_NAME)\n",
    "vectorstore = Pinecone(index, embeddings.embed_query, \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": prompt,\n",
    "        \"parameters\" : {**model_kwargs}})\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-09 18:01:38.840 Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "content_handler = ContentHandler()\n",
    "\n",
    "llm=SagemakerEndpoint(\n",
    "     endpoint_name=endpoint_name, \n",
    "     region_name=region, \n",
    "     model_kwargs={\"max_new_tokens\": 200, \"top_p\": 0.9, \"max_length\": None, \"temperature\":1e-10},\n",
    "     endpoint_kwargs={\"CustomAttributes\": 'accept_eula=true'},\n",
    "     content_handler=content_handler,\n",
    "     credentials_profile_name=\"fundamentl-ai\"\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(prompt=QA_CHAIN_PROMPT, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the capital of France?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "example_doc_1 = \"\"\"\n",
    "Peter and Elizabeth took a taxi to attend the night party in the city. While in the party, Elizabeth collapsed and was rushed to the hospital.\n",
    "Since she was diagnosed with a brain injury, the doctor told Peter to stay besides her until she gets well.\n",
    "Therefore, Peter stayed with her at the hospital for 3 days without leaving.\n",
    "\"\"\"\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=example_doc_1,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qa = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever(), chain_type=\"stuff\", return_source_documents=True, chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template = \"\"\"\n",
    "# The following is a friendly conversation between a human and an AI. \n",
    "# The AI is talkative and provides lots of specific details from its context.\n",
    "# If the AI does not know the answer to a question, it truthfully says it \n",
    "# does not know.\n",
    "# {context}\n",
    "# Instruction: Based on the above documents, provide a detailed answer for, {question} Answer \"don't know\" \n",
    "# if not present in the document. \n",
    "# Solution:\"\"\"\n",
    "# PROMPT = PromptTemplate(\n",
    "#     template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    "# )\n",
    "# chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=vectorstore.as_retriever(), \n",
    "    #chain_type_kwargs=chain_type_kwargs,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error raised by inference endpoint: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint huggingface-pytorch-tgi-inference-2023-08-09-22-11-09-254 of account 653844554812 not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/llms/sagemaker_endpoint.py:236\u001b[0m, in \u001b[0;36mSagemakerEndpoint._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49minvoke_endpoint(\n\u001b[1;32m    237\u001b[0m         EndpointName\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mendpoint_name,\n\u001b[1;32m    238\u001b[0m         Body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    239\u001b[0m         ContentType\u001b[39m=\u001b[39;49mcontent_type,\n\u001b[1;32m    240\u001b[0m         Accept\u001b[39m=\u001b[39;49maccepts,\n\u001b[1;32m    241\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_endpoint_kwargs,\n\u001b[1;32m    242\u001b[0m     )\n\u001b[1;32m    243\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/botocore/client.py:534\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 534\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/botocore/client.py:976\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    975\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 976\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    977\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValidationError\u001b[0m: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint huggingface-pytorch-tgi-inference-2023-08-09-22-11-09-254 of account 653844554812 not found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[39m=\u001b[39m qa_chain({\u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mWhat is rainfall data?\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/chains/base.py:243\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    244\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    245\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    246\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    247\u001b[0m )\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/chains/base.py:237\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    231\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    232\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    233\u001b[0m     inputs,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 237\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    238\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    239\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/chains/retrieval_qa/base.py:131\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     docs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_docs(question)  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_documents_chain\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    132\u001b[0m     input_documents\u001b[39m=\u001b[39;49mdocs, question\u001b[39m=\u001b[39;49mquestion, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child()\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_source_documents:\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key: answer, \u001b[39m\"\u001b[39m\u001b[39msource_documents\u001b[39m\u001b[39m\"\u001b[39m: docs}\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/chains/base.py:445\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[1;32m    441\u001b[0m         _output_key\n\u001b[1;32m    442\u001b[0m     ]\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m--> 445\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[1;32m    446\u001b[0m         _output_key\n\u001b[1;32m    447\u001b[0m     ]\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    450\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    451\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but none were provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m     )\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/chains/base.py:243\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    244\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    245\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    246\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    247\u001b[0m )\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/chains/base.py:237\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    231\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    232\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    233\u001b[0m     inputs,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 237\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    238\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    239\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py:106\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    105\u001b[0m other_keys \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m inputs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_key}\n\u001b[0;32m--> 106\u001b[0m output, extra_return_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcombine_docs(\n\u001b[1;32m    107\u001b[0m     docs, callbacks\u001b[39m=\u001b[39;49m_run_manager\u001b[39m.\u001b[39;49mget_child(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mother_keys\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    109\u001b[0m extra_return_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key] \u001b[39m=\u001b[39m output\n\u001b[1;32m    110\u001b[0m \u001b[39mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/chains/combine_documents/stuff.py:165\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_inputs(docs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[39m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_chain\u001b[39m.\u001b[39;49mpredict(callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minputs), {}\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/chains/llm.py:252\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    238\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \n\u001b[1;32m    240\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/chains/base.py:243\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 243\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    244\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    245\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[1;32m    246\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    247\u001b[0m )\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/chains/base.py:237\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    231\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    232\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[1;32m    233\u001b[0m     inputs,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 237\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m    238\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    239\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    242\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/chains/llm.py:92\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[1;32m     88\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     89\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[1;32m     90\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     91\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m---> 92\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([inputs], run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[1;32m     93\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/chains/llm.py:102\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate LLM result from inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m prompts, stop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_prompts(input_list, run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[1;32m    103\u001b[0m     prompts,\n\u001b[1;32m    104\u001b[0m     stop,\n\u001b[1;32m    105\u001b[0m     callbacks\u001b[39m=\u001b[39;49mrun_manager\u001b[39m.\u001b[39;49mget_child() \u001b[39mif\u001b[39;49;00m run_manager \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    106\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm_kwargs,\n\u001b[1;32m    107\u001b[0m )\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/llms/base.py:186\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    180\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    184\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    185\u001b[0m     prompt_strings \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_string() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[0;32m--> 186\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_strings, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/llms/base.py:279\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    274\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m         )\n\u001b[1;32m    276\u001b[0m     run_managers \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    277\u001b[0m         dumpd(\u001b[39mself\u001b[39m), prompts, invocation_params\u001b[39m=\u001b[39mparams, options\u001b[39m=\u001b[39moptions\n\u001b[1;32m    278\u001b[0m     )\n\u001b[0;32m--> 279\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_helper(\n\u001b[1;32m    280\u001b[0m         prompts, stop, run_managers, \u001b[39mbool\u001b[39;49m(new_arg_supported), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing_prompts) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/llms/base.py:223\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n\u001b[1;32m    222\u001b[0m         run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 223\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    224\u001b[0m flattened_outputs \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m    225\u001b[0m \u001b[39mfor\u001b[39;00m manager, flattened_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/llms/base.py:210\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_helper\u001b[39m(\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    202\u001b[0m     prompts: List[\u001b[39mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    207\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[1;32m    208\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m         output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 210\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    211\u001b[0m                 prompts,\n\u001b[1;32m    212\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[1;32m    213\u001b[0m                 \u001b[39m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    214\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    215\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    216\u001b[0m             )\n\u001b[1;32m    217\u001b[0m             \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    218\u001b[0m             \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m    219\u001b[0m         )\n\u001b[1;32m    220\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    221\u001b[0m         \u001b[39mfor\u001b[39;00m run_manager \u001b[39min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/llms/base.py:602\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    600\u001b[0m \u001b[39mfor\u001b[39;00m prompt \u001b[39min\u001b[39;00m prompts:\n\u001b[1;32m    601\u001b[0m     text \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 602\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(prompt, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    603\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    604\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(prompt, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m     generations\u001b[39m.\u001b[39mappend([Generation(text\u001b[39m=\u001b[39mtext)])\n\u001b[1;32m    607\u001b[0m \u001b[39mreturn\u001b[39;00m LLMResult(generations\u001b[39m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/FundamentlPartners/abinvenv-sol/venv/lib/python3.10/site-packages/langchain/llms/sagemaker_endpoint.py:244\u001b[0m, in \u001b[0;36mSagemakerEndpoint._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39minvoke_endpoint(\n\u001b[1;32m    237\u001b[0m         EndpointName\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendpoint_name,\n\u001b[1;32m    238\u001b[0m         Body\u001b[39m=\u001b[39mbody,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_endpoint_kwargs,\n\u001b[1;32m    242\u001b[0m     )\n\u001b[1;32m    243\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 244\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError raised by inference endpoint: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    246\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontent_handler\u001b[39m.\u001b[39mtransform_output(response[\u001b[39m\"\u001b[39m\u001b[39mBody\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    247\u001b[0m \u001b[39mif\u001b[39;00m stop \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     \u001b[39m# This is a bit hacky, but I can't figure out a better way to enforce\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39m# stop tokens when making calls to the sagemaker endpoint.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Error raised by inference endpoint: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint huggingface-pytorch-tgi-inference-2023-08-09-22-11-09-254 of account 653844554812 not found."
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\":\"What is rainfall data?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is rainfall data?',\n",
       " 'result': \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nIn order to help correct for the inaccuracies and errors that are present in the two types of data and take advantage of their individual strengths, research institutions have produced rainfall datasets that combine station and satellite/radar observations. Datasets that combine these observations are the recommended source of data for humanitarian purposes.\\n\\nObservational precipitation data can be presented in various formats, each providing unique insights into precipitation patterns. The most common representation is through absolute values, which reflect the actual amount of precipitation observed at a specific location and time, typically measured in millimeters. Precipitation averages, which are calculated from historical records over a period of typically at least 10 years, can be produced for a specific location, season, or year. A precipitation anomaly represents the deviation from the expected or average precipitation over a particular period, which can be expressed as a difference in millimeters or as a percentage. The purpose of the analysis determines the most useful representation. Absolute values provide insight into the total precipitation received at a location, while anomalies and averages help to understand long-term trends, including dry or wet periods, which is valuable for assessing drought or excessive rainfall conditions severity.\\n\\nCENTRE FOR HUMANITARIAN DATA\\n\\n3\\n\\nCommon sources of observational rainfall data\\n\\nAmong the many sources of data available, we introduce here two common sources of observational rainfall data, both of which combine station and satellite data: CHIRPS and ARC2. CHIRPS refers to the Climate Hazards Group InfraRed Precipitation with Station data and is produced by scientists from the US Geological Survey and the Climate Hazards Center at the University of Santa Barbara. ARC2 refers to Africa Rainfall Climatology Version 2 and it is produced by The National Oceanic and Atmospheric Administration’s Climate Prediction Center for the Famine Early Warning System. You can access the data directly from these providers, or use the tabular CHIRPS datasets that provides pre-computed rainfall metrics at admin2 and is available on HDX.1\\n\\nIn order to help correct for the inaccuracies and errors that are present in the two types of data and take advantage of their individual strengths, research institutions have produced rainfall datasets that combine station and satellite/radar observations. Datasets that combine these observations are the recommended source of data for humanitarian purposes.\\n\\nObservational precipitation data can be presented in various formats, each providing unique insights into precipitation patterns. The most common representation is through absolute values, which reflect the actual amount of precipitation observed at a specific location and time, typically measured in millimeters. Precipitation averages, which are calculated from historical records over a period of typically at least 10 years, can be produced for a specific location, season, or year. A precipitation anomaly represents the deviation from the expected or average precipitation over a particular period, which can be expressed as a difference in millimeters or as a percentage. The purpose of the analysis determines the most useful representation. Absolute values provide insight into the total precipitation received at a location, while anomalies and averages help to understand long-term trends, including dry or wet periods, which is valuable for assessing drought or excessive rainfall conditions severity.\\n\\nCENTRE FOR HUMANITARIAN DATA\\n\\n3\\n\\nCommon sources of observational rainfall data\\n\\nAmong the many sources of data available, we introduce here two common sources of observational rainfall data, both of which combine station and satellite data: CHIRPS and ARC2. CHIRPS refers to the Climate Hazards Group InfraRed Precipitation with Station data and is produced by scientists from the US Geological Survey and the Climate Hazards Center at the University of Santa Barbara. ARC2 refers to Africa Rainfall Climatology Version 2 and it is produced by The National Oceanic and Atmospheric Administration’s Climate Prediction Center for the Famine Early Warning System. You can access the data directly from these providers, or use the tabular CHIRPS datasets that provides pre-computed rainfall metrics at admin2 and is available on HDX.1\\n\\nObservational rainfall data is produced by measuring the amount of rainfall at precise locations, which are called measuring stations or gauges (e.g., the stars in Figure 1 below). Station data is typically obtained from national or regional meteorological services and should only be used in accordance with their guidance. Some of the advantages of station data are that it is accurate at the specific locations, it is collected frequently and it has been collected over the long-term, allowing for trend analysis. On the other hand, station data is only available for specific locations and is subject to bias due to wind, evaporation, and changes in measurement devices. Contact the local or regional meteorological services to learn whether station data is available, where the stations are located, how often the data is updated, and whether historical records are available.\\n\\nCENTRE FOR HUMANITARIAN DATA\\n\\n2\\n\\nRainfall can also be estimated using satellite or radar images that cover areas several square kilometers wide (e.g., the squares in Figure 1 below). Satellite imagery is typically obtained by global providers and academic or research centers (e.g., the Climate Hazards Center) who share their derived estimates publicly. Satellite or radar images are useful for understanding patterns over larger geographic areas. Some of the advantages of satellite data are that it has extensive geographic coverage, including in remote and inaccessible areas, and that it is shared in a continuous and consistent way. On the other hand, satellite measurements are subject to errors due to cloud contamination, and the data has a shorter historical record.\\n\\nFigure 1. Weather Stations in Zambia (red stars). The grid superimposed onto the map consists of individual boxes, each of which corresponds to a particular location where satellite weather measurements are conducted by certain providers. In this case, the grid is the one used by the ARC2 dataset (see below). The size of each box is 0.1 degree (about 11 km at the equator).\\n\\nObservational rainfall data is produced by measuring the amount of rainfall at precise locations, which are called measuring stations or gauges (e.g., the stars in Figure 1 below). Station data is typically obtained from national or regional meteorological services and should only be used in accordance with their guidance. Some of the advantages of station data are that it is accurate at the specific locations, it is collected frequently and it has been collected over the long-term, allowing for trend analysis. On the other hand, station data is only available for specific locations and is subject to bias due to wind, evaporation, and changes in measurement devices. Contact the local or regional meteorological services to learn whether station data is available, where the stations are located, how often the data is updated, and whether historical records are available.\\n\\nCENTRE FOR HUMANITARIAN DATA\\n\\n2\\n\\nRainfall can also be estimated using satellite or radar images that cover areas several square kilometers wide (e.g., the squares in Figure 1 below). Satellite imagery is typically obtained by global providers and academic or research centers (e.g., the Climate Hazards Center) who share their derived estimates publicly. Satellite or radar images are useful for understanding patterns over larger geographic areas. Some of the advantages of satellite data are that it has extensive geographic coverage, including in remote and inaccessible areas, and that it is shared in a continuous and consistent way. On the other hand, satellite measurements are subject to errors due to cloud contamination, and the data has a shorter historical record.\\n\\nFigure 1. Weather Stations in Zambia (red stars). The grid superimposed onto the map consists of individual boxes, each of which corresponds to a particular location where satellite weather measurements are conducted by certain providers. In this case, the grid is the one used by the ARC2 dataset (see below). The size of each box is 0.1 degree (about 11 km at the equator).\\n\\nQuestion: What is rainfall data?\\nHelpful Answer:\",\n",
       " 'source_documents': [Document(page_content='In order to help correct for the inaccuracies and errors that are present in the two types of data and take advantage of their individual strengths, research institutions have produced rainfall datasets that combine station and satellite/radar observations. Datasets that combine these observations are the recommended source of data for humanitarian purposes.\\n\\nObservational precipitation data can be presented in various formats, each providing unique insights into precipitation patterns. The most common representation is through absolute values, which reflect the actual amount of precipitation observed at a specific location and time, typically measured in millimeters. Precipitation averages, which are calculated from historical records over a period of typically at least 10 years, can be produced for a specific location, season, or year. A precipitation anomaly represents the deviation from the expected or average precipitation over a particular period, which can be expressed as a difference in millimeters or as a percentage. The purpose of the analysis determines the most useful representation. Absolute values provide insight into the total precipitation received at a location, while anomalies and averages help to understand long-term trends, including dry or wet periods, which is valuable for assessing drought or excessive rainfall conditions severity.\\n\\nCENTRE FOR HUMANITARIAN DATA\\n\\n3\\n\\nCommon sources of observational rainfall data\\n\\nAmong the many sources of data available, we introduce here two common sources of observational rainfall data, both of which combine station and satellite data: CHIRPS and ARC2. CHIRPS refers to the Climate Hazards Group InfraRed Precipitation with Station data and is produced by scientists from the US Geological Survey and the Climate Hazards Center at the University of Santa Barbara. ARC2 refers to Africa Rainfall Climatology Version 2 and it is produced by The National Oceanic and Atmospheric Administration’s Climate Prediction Center for the Famine Early Warning System. You can access the data directly from these providers, or use the tabular CHIRPS datasets that provides pre-computed rainfall metrics at admin2 and is available on HDX.1', metadata={'chunk': 2.0, 'data_source': 'Local', 'id': 'cff59eebaaf740dca3bd4f7e825cc89c', 'page': 'None', 'source': 'guidance_observationalrainfalldata.pdf'}),\n",
       "  Document(page_content='In order to help correct for the inaccuracies and errors that are present in the two types of data and take advantage of their individual strengths, research institutions have produced rainfall datasets that combine station and satellite/radar observations. Datasets that combine these observations are the recommended source of data for humanitarian purposes.\\n\\nObservational precipitation data can be presented in various formats, each providing unique insights into precipitation patterns. The most common representation is through absolute values, which reflect the actual amount of precipitation observed at a specific location and time, typically measured in millimeters. Precipitation averages, which are calculated from historical records over a period of typically at least 10 years, can be produced for a specific location, season, or year. A precipitation anomaly represents the deviation from the expected or average precipitation over a particular period, which can be expressed as a difference in millimeters or as a percentage. The purpose of the analysis determines the most useful representation. Absolute values provide insight into the total precipitation received at a location, while anomalies and averages help to understand long-term trends, including dry or wet periods, which is valuable for assessing drought or excessive rainfall conditions severity.\\n\\nCENTRE FOR HUMANITARIAN DATA\\n\\n3\\n\\nCommon sources of observational rainfall data\\n\\nAmong the many sources of data available, we introduce here two common sources of observational rainfall data, both of which combine station and satellite data: CHIRPS and ARC2. CHIRPS refers to the Climate Hazards Group InfraRed Precipitation with Station data and is produced by scientists from the US Geological Survey and the Climate Hazards Center at the University of Santa Barbara. ARC2 refers to Africa Rainfall Climatology Version 2 and it is produced by The National Oceanic and Atmospheric Administration’s Climate Prediction Center for the Famine Early Warning System. You can access the data directly from these providers, or use the tabular CHIRPS datasets that provides pre-computed rainfall metrics at admin2 and is available on HDX.1', metadata={'chunk': 2.0, 'data_source': 'Local', 'id': 'cb6ace0becdb4476b782b02dbe02712f', 'page': 'None', 'source': 'guidance_observationalrainfalldata.pdf'}),\n",
       "  Document(page_content='Observational rainfall data is produced by measuring the amount of rainfall at precise locations, which are called measuring stations or gauges (e.g., the stars in Figure 1 below). Station data is typically obtained from national or regional meteorological services and should only be used in accordance with their guidance. Some of the advantages of station data are that it is accurate at the specific locations, it is collected frequently and it has been collected over the long-term, allowing for trend analysis. On the other hand, station data is only available for specific locations and is subject to bias due to wind, evaporation, and changes in measurement devices. Contact the local or regional meteorological services to learn whether station data is available, where the stations are located, how often the data is updated, and whether historical records are available.\\n\\nCENTRE FOR HUMANITARIAN DATA\\n\\n2\\n\\nRainfall can also be estimated using satellite or radar images that cover areas several square kilometers wide (e.g., the squares in Figure 1 below). Satellite imagery is typically obtained by global providers and academic or research centers (e.g., the Climate Hazards Center) who share their derived estimates publicly. Satellite or radar images are useful for understanding patterns over larger geographic areas. Some of the advantages of satellite data are that it has extensive geographic coverage, including in remote and inaccessible areas, and that it is shared in a continuous and consistent way. On the other hand, satellite measurements are subject to errors due to cloud contamination, and the data has a shorter historical record.\\n\\nFigure 1. Weather Stations in Zambia (red stars). The grid superimposed onto the map consists of individual boxes, each of which corresponds to a particular location where satellite weather measurements are conducted by certain providers. In this case, the grid is the one used by the ARC2 dataset (see below). The size of each box is 0.1 degree (about 11 km at the equator).', metadata={'chunk': 1.0, 'data_source': 'Local', 'id': 'cb6ace0becdb4476b782b02dbe02712f', 'page': 'None', 'source': 'guidance_observationalrainfalldata.pdf'}),\n",
       "  Document(page_content='Observational rainfall data is produced by measuring the amount of rainfall at precise locations, which are called measuring stations or gauges (e.g., the stars in Figure 1 below). Station data is typically obtained from national or regional meteorological services and should only be used in accordance with their guidance. Some of the advantages of station data are that it is accurate at the specific locations, it is collected frequently and it has been collected over the long-term, allowing for trend analysis. On the other hand, station data is only available for specific locations and is subject to bias due to wind, evaporation, and changes in measurement devices. Contact the local or regional meteorological services to learn whether station data is available, where the stations are located, how often the data is updated, and whether historical records are available.\\n\\nCENTRE FOR HUMANITARIAN DATA\\n\\n2\\n\\nRainfall can also be estimated using satellite or radar images that cover areas several square kilometers wide (e.g., the squares in Figure 1 below). Satellite imagery is typically obtained by global providers and academic or research centers (e.g., the Climate Hazards Center) who share their derived estimates publicly. Satellite or radar images are useful for understanding patterns over larger geographic areas. Some of the advantages of satellite data are that it has extensive geographic coverage, including in remote and inaccessible areas, and that it is shared in a continuous and consistent way. On the other hand, satellite measurements are subject to errors due to cloud contamination, and the data has a shorter historical record.\\n\\nFigure 1. Weather Stations in Zambia (red stars). The grid superimposed onto the map consists of individual boxes, each of which corresponds to a particular location where satellite weather measurements are conducted by certain providers. In this case, the grid is the one used by the ARC2 dataset (see below). The size of each box is 0.1 degree (about 11 km at the equator).', metadata={'chunk': 1.0, 'data_source': 'Local', 'id': 'cff59eebaaf740dca3bd4f7e825cc89c', 'page': 'None', 'source': 'guidance_observationalrainfalldata.pdf'})]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CENTRE FOR HUMANITARIAN DATA'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result'].split('\\n')[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='In order to help correct for the inaccuracies and errors that are present in the two types of data and take advantage of their individual strengths, research institutions have produced rainfall datasets that combine station and satellite/radar observations. Datasets that combine these observations are the recommended source of data for humanitarian purposes.\\n\\nObservational precipitation data can be presented in various formats, each providing unique insights into precipitation patterns. The most common representation is through absolute values, which reflect the actual amount of precipitation observed at a specific location and time, typically measured in millimeters. Precipitation averages, which are calculated from historical records over a period of typically at least 10 years, can be produced for a specific location, season, or year. A precipitation anomaly represents the deviation from the expected or average precipitation over a particular period, which can be expressed as a difference in millimeters or as a percentage. The purpose of the analysis determines the most useful representation. Absolute values provide insight into the total precipitation received at a location, while anomalies and averages help to understand long-term trends, including dry or wet periods, which is valuable for assessing drought or excessive rainfall conditions severity.\\n\\nCENTRE FOR HUMANITARIAN DATA\\n\\n3\\n\\nCommon sources of observational rainfall data\\n\\nAmong the many sources of data available, we introduce here two common sources of observational rainfall data, both of which combine station and satellite data: CHIRPS and ARC2. CHIRPS refers to the Climate Hazards Group InfraRed Precipitation with Station data and is produced by scientists from the US Geological Survey and the Climate Hazards Center at the University of Santa Barbara. ARC2 refers to Africa Rainfall Climatology Version 2 and it is produced by The National Oceanic and Atmospheric Administration’s Climate Prediction Center for the Famine Early Warning System. You can access the data directly from these providers, or use the tabular CHIRPS datasets that provides pre-computed rainfall metrics at admin2 and is available on HDX.1', metadata={'chunk': 2.0, 'data_source': 'Local', 'id': 'cff59eebaaf740dca3bd4f7e825cc89c', 'page': 'None', 'source': 'guidance_observationalrainfalldata.pdf'}),\n",
       " Document(page_content='In order to help correct for the inaccuracies and errors that are present in the two types of data and take advantage of their individual strengths, research institutions have produced rainfall datasets that combine station and satellite/radar observations. Datasets that combine these observations are the recommended source of data for humanitarian purposes.\\n\\nObservational precipitation data can be presented in various formats, each providing unique insights into precipitation patterns. The most common representation is through absolute values, which reflect the actual amount of precipitation observed at a specific location and time, typically measured in millimeters. Precipitation averages, which are calculated from historical records over a period of typically at least 10 years, can be produced for a specific location, season, or year. A precipitation anomaly represents the deviation from the expected or average precipitation over a particular period, which can be expressed as a difference in millimeters or as a percentage. The purpose of the analysis determines the most useful representation. Absolute values provide insight into the total precipitation received at a location, while anomalies and averages help to understand long-term trends, including dry or wet periods, which is valuable for assessing drought or excessive rainfall conditions severity.\\n\\nCENTRE FOR HUMANITARIAN DATA\\n\\n3\\n\\nCommon sources of observational rainfall data\\n\\nAmong the many sources of data available, we introduce here two common sources of observational rainfall data, both of which combine station and satellite data: CHIRPS and ARC2. CHIRPS refers to the Climate Hazards Group InfraRed Precipitation with Station data and is produced by scientists from the US Geological Survey and the Climate Hazards Center at the University of Santa Barbara. ARC2 refers to Africa Rainfall Climatology Version 2 and it is produced by The National Oceanic and Atmospheric Administration’s Climate Prediction Center for the Famine Early Warning System. You can access the data directly from these providers, or use the tabular CHIRPS datasets that provides pre-computed rainfall metrics at admin2 and is available on HDX.1', metadata={'chunk': 2.0, 'data_source': 'Local', 'id': 'cb6ace0becdb4476b782b02dbe02712f', 'page': 'None', 'source': 'guidance_observationalrainfalldata.pdf'}),\n",
       " Document(page_content='Observational rainfall data is produced by measuring the amount of rainfall at precise locations, which are called measuring stations or gauges (e.g., the stars in Figure 1 below). Station data is typically obtained from national or regional meteorological services and should only be used in accordance with their guidance. Some of the advantages of station data are that it is accurate at the specific locations, it is collected frequently and it has been collected over the long-term, allowing for trend analysis. On the other hand, station data is only available for specific locations and is subject to bias due to wind, evaporation, and changes in measurement devices. Contact the local or regional meteorological services to learn whether station data is available, where the stations are located, how often the data is updated, and whether historical records are available.\\n\\nCENTRE FOR HUMANITARIAN DATA\\n\\n2\\n\\nRainfall can also be estimated using satellite or radar images that cover areas several square kilometers wide (e.g., the squares in Figure 1 below). Satellite imagery is typically obtained by global providers and academic or research centers (e.g., the Climate Hazards Center) who share their derived estimates publicly. Satellite or radar images are useful for understanding patterns over larger geographic areas. Some of the advantages of satellite data are that it has extensive geographic coverage, including in remote and inaccessible areas, and that it is shared in a continuous and consistent way. On the other hand, satellite measurements are subject to errors due to cloud contamination, and the data has a shorter historical record.\\n\\nFigure 1. Weather Stations in Zambia (red stars). The grid superimposed onto the map consists of individual boxes, each of which corresponds to a particular location where satellite weather measurements are conducted by certain providers. In this case, the grid is the one used by the ARC2 dataset (see below). The size of each box is 0.1 degree (about 11 km at the equator).', metadata={'chunk': 1.0, 'data_source': 'Local', 'id': 'cb6ace0becdb4476b782b02dbe02712f', 'page': 'None', 'source': 'guidance_observationalrainfalldata.pdf'}),\n",
       " Document(page_content='Observational rainfall data is produced by measuring the amount of rainfall at precise locations, which are called measuring stations or gauges (e.g., the stars in Figure 1 below). Station data is typically obtained from national or regional meteorological services and should only be used in accordance with their guidance. Some of the advantages of station data are that it is accurate at the specific locations, it is collected frequently and it has been collected over the long-term, allowing for trend analysis. On the other hand, station data is only available for specific locations and is subject to bias due to wind, evaporation, and changes in measurement devices. Contact the local or regional meteorological services to learn whether station data is available, where the stations are located, how often the data is updated, and whether historical records are available.\\n\\nCENTRE FOR HUMANITARIAN DATA\\n\\n2\\n\\nRainfall can also be estimated using satellite or radar images that cover areas several square kilometers wide (e.g., the squares in Figure 1 below). Satellite imagery is typically obtained by global providers and academic or research centers (e.g., the Climate Hazards Center) who share their derived estimates publicly. Satellite or radar images are useful for understanding patterns over larger geographic areas. Some of the advantages of satellite data are that it has extensive geographic coverage, including in remote and inaccessible areas, and that it is shared in a continuous and consistent way. On the other hand, satellite measurements are subject to errors due to cloud contamination, and the data has a shorter historical record.\\n\\nFigure 1. Weather Stations in Zambia (red stars). The grid superimposed onto the map consists of individual boxes, each of which corresponds to a particular location where satellite weather measurements are conducted by certain providers. In this case, the grid is the one used by the ARC2 dataset (see below). The size of each box is 0.1 degree (about 11 km at the equator).', metadata={'chunk': 1.0, 'data_source': 'Local', 'id': 'cff59eebaaf740dca3bd4f7e825cc89c', 'page': 'None', 'source': 'guidance_observationalrainfalldata.pdf'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['source_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is Twitter?',\n",
       " 'result': \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nEnguehard, C. 1994. Acquisition of terminology from colloquial texts. In Proceedings, Computational Linguistics for Speech and Handwriting Recognition (CLSHR).\\n\\nGrefenstette, G. 1994. Explorations in Automatic Thesaurus Discovery. Dordrecht, The Netherlands: Kluwer Academic Publisher.\\n\\nJacquemin, C. 1994. Recycling terms into a partial parser. In Proceedings, 4th Conference on Applied Natural Language Processing (ANLP'94),  113-118.\\n\\nLewis, D. D., and Croft, W. B. 1990. Term clustering of syntactic phrasess. In Proceedings, 13th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'90),  385-404.\\n\\nResnik, P. 1993. Selection and Information : A Class-Based Approach to Lexical Relationships. Ph.D. thesis, University of Pennsylvania, Institute for Research in Cognitive Science.\\n\\nShieber, S. N. 1986. An Introduction to Unification-Based Approaches to Grammar. CSLI Lecture Notes 4. Stanford, CA: CSLI.\\n\\nSmadja, F. 1993. Xtract : An overview. Computer and the Humanities 26:399-413.\\n\\nFootnotes\\n\\nMatched control is a partial term with a missing noun argument which is not ruled out by our acquisition process. With a proper acquisition, this term would not appear as a candidate and the links issuing from this term would issue from one of the correct terms tex2html_wrap_inline$$Nountex2html_wrap_inline$$matched control. Among these 71,623 terms, only 12,717 are found in the [Medic] corpus under their basic form or one of its correct variants.\\n\\nHerbert H. Clark and Catherine R. Marshall. Definite reference and mutual knowledge. In Joshi, Webber, and Sag, editors, Elements of Discourse Understanding, pages 10-63. CUP, Cambridge, 1981.\\n\\nHerbert H. Clark and Edward F. Schaefer. Contributing to discourse. Cognitive Science, 13:259-294, 1989.\\n\\nJulia R. Galliers. Cooperative interaction as strategic belief revision. In M.S. Deen, editor, Cooperating Knowledge Based Systems, page 1. Springer Verlag, 1991.\\n\\nH. P. Grice.\\n\\nWilliam James Lectures.\\n\\n1967.\\n\\nBarbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. Towards a computational theory of discourse interpretation. Unpublished Manuscript, 1986.\\n\\nBarbara J. Grosz and Candace L. Sidner. Attentions, intentions and the structure of discourse. Computational Linguistics, 12:175-204, 1986.\\n\\nBarbara J. Grosz and Candace L. Sidner. Plans for discourse. In Cohen, Morgan and Pollack, eds. Intentions in Communication, MIT Press, 1990.\\n\\nJulia Hirschberg. A Theory of Scalar Implicature. PhD thesis, University of Pennsylvania, Computer and Information Science, 1985.\\n\\nDavid Lewis.\\n\\nConvention.\\n\\nHarvard University Press, 1969.\\n\\nDiane Litman and James Allen. Recognizing and relating discourse intentions and task-oriented plans. In Cohen, Morgan and Pollack, eds. Intentions in Communication, MIT Press, 1990.\\n\\nMartha Pollack, Julia Hirschberg, and Bonnie Webber. User participation in the reasoning process of expert systems. In AAAI82, 1982.\\n\\nComputational Linguistics 16(1):1\\n\\n\\n\\n10.\\n\\nPereira, F. C. N., and M. E. Pollack. 1991. Incremental Interpretation. Artificial Intelligence 50:37-82.\\n\\nPinkal, M. 1985. Logik und Lexikon: Die Semantik des Unbestimmten. Berlin: de Gruyter.\\n\\nPinkal, M. 1995.\\n\\nLogic and Lexicon.\\n\\nLondon: Oxford.\\n\\nPoesio, M. 1991. Relational Semantics and Scope Ambiguity. In Situation Semantics and its Applications, vol.2, ed. J. Barwise, J. M. Gawron, G. Plotkin, and S. Tutiya. Chap. 20, 469-497. Stanford, CA: CSLI.\\n\\nPoesio, M. 1994. Discourse Interpretation and the Scope of Operators. Doctoral dissertation, University of Rochester, Department of Computer Science, Rochester, NY.\\n\\nPoesio, M. 1995. A Model of Conversation Processing Based on Micro Conversational Events. In Proceedings of the Annual Meeting of the Cognitive Science Society. Pittsburgh.\\n\\nRaskin, V. 1985. Semantic Mechanisms of Humor. Dordrecht and Boston: D. Reidel.\\n\\nReiter, R. 1980. A Logic for Default Reasoning. Artificial Intelligence 13(1-2):81-132.\\n\\nReyle, U. 1993. Dealing with ambiguities by underspecification: Construction, Representation and Deduction. Journal of Semantics 3.\\n\\nRodman, R. 1976. Scope Phenomena, ``Movement Transformations,'' and Relative Clauses. In Montague Grammar, ed. Barbara Partee. 165-176. Academic Press.\\n\\nThese materials are © 2018 John Wiley & Sons, Inc. Any dissemination, distribution, or unauthorized use is strictly prohibited.Table of Contents\\nINTRODUCTION  ............................................................................................... 1\\nAbout This Book  ................................................................................... 1\\nFoolish Assumptions  ............................................................................ 2\\nIcons Used in This Book  ....................................................................... 2\\nCHAPTER 1:  Grasping Blockchain Fundamentals  ............................ 3\\nTracing Blockchain’s Origin  ................................................................. 3\\nThe shortcomings of current  transaction systems ..................... 4\\nThe emergence of Bitcoin  .............................................................. 5\\nThe birth of blockchain  .................................................................. 6\\nRevolutionizing the Traditional Business Network  .......................... 6\\nExploring a blockchain application  ............................................... 7\\nRecognizing the key business benefits  ......................................... 9\\nBuilding trust with blockchain  ..................................................... 10\\nCHAPTER 2:  Taking a Look at How Blockchain Works  ............... 13\\nWhy It’s Called “Blockchain”  .............................................................. 13\\nWhat Makes a Blockchain Suitable for Business?  .......................... 14\\nShared ledger  ................................................................................ 15\\nPermissions ................................................................................... 15\\nConsensus ...................................................................................... 16\\nSmart contracts ............................................................................. 17\\nIdentifying Participants and Their Roles  .......................................... 18\\nCHAPTER 3:  Propelling Business with Blockchains  ...................... 19\\nRecognizing Types of Market Friction  .............................................. 20\\nInformation frictions ..................................................................... 20\\nInteraction frictions  ...................................................................... 20\\nInnovation frictions  ....................................................................... 21\\nMoving Closer to Friction-Free Business Networks  ....................... 21\\nReducing information friction  ..................................................... 22\\nEasing interaction friction  ............................................................ 22\\nEasing innovation friction  ............................................................ 23\\nTransforming Ecosystems through Increased Visibility  ................. 24\\nTable of Contents      iii\\n\\nQuestion: What is Twitter?\\nHelpful Answer:\",\n",
       " 'source_documents': [Document(page_content=\"Enguehard, C. 1994. Acquisition of terminology from colloquial texts. In Proceedings, Computational Linguistics for Speech and Handwriting Recognition (CLSHR).\\n\\nGrefenstette, G. 1994. Explorations in Automatic Thesaurus Discovery. Dordrecht, The Netherlands: Kluwer Academic Publisher.\\n\\nJacquemin, C. 1994. Recycling terms into a partial parser. In Proceedings, 4th Conference on Applied Natural Language Processing (ANLP'94),  113-118.\\n\\nLewis, D. D., and Croft, W. B. 1990. Term clustering of syntactic phrasess. In Proceedings, 13th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'90),  385-404.\\n\\nResnik, P. 1993. Selection and Information : A Class-Based Approach to Lexical Relationships. Ph.D. thesis, University of Pennsylvania, Institute for Research in Cognitive Science.\\n\\nShieber, S. N. 1986. An Introduction to Unification-Based Approaches to Grammar. CSLI Lecture Notes 4. Stanford, CA: CSLI.\\n\\nSmadja, F. 1993. Xtract : An overview. Computer and the Humanities 26:399-413.\\n\\nFootnotes\\n\\nMatched control is a partial term with a missing noun argument which is not ruled out by our acquisition process. With a proper acquisition, this term would not appear as a candidate and the links issuing from this term would issue from one of the correct terms tex2html_wrap_inline$$Nountex2html_wrap_inline$$matched control. Among these 71,623 terms, only 12,717 are found in the [Medic] corpus under their basic form or one of its correct variants.\", metadata={'chunk': 5.0, 'data_source': 'Local', 'id': '70039058579349d496c8b1a52bf09e60', 'page': 'None', 'source': '9505012.xml'}),\n",
       "  Document(page_content='Herbert H. Clark and Catherine R. Marshall. Definite reference and mutual knowledge. In Joshi, Webber, and Sag, editors, Elements of Discourse Understanding, pages 10-63. CUP, Cambridge, 1981.\\n\\nHerbert H. Clark and Edward F. Schaefer. Contributing to discourse. Cognitive Science, 13:259-294, 1989.\\n\\nJulia R. Galliers. Cooperative interaction as strategic belief revision. In M.S. Deen, editor, Cooperating Knowledge Based Systems, page 1. Springer Verlag, 1991.\\n\\nH. P. Grice.\\n\\nWilliam James Lectures.\\n\\n1967.\\n\\nBarbara J. Grosz, Aravind K. Joshi, and Scott Weinstein. Towards a computational theory of discourse interpretation. Unpublished Manuscript, 1986.\\n\\nBarbara J. Grosz and Candace L. Sidner. Attentions, intentions and the structure of discourse. Computational Linguistics, 12:175-204, 1986.\\n\\nBarbara J. Grosz and Candace L. Sidner. Plans for discourse. In Cohen, Morgan and Pollack, eds. Intentions in Communication, MIT Press, 1990.\\n\\nJulia Hirschberg. A Theory of Scalar Implicature. PhD thesis, University of Pennsylvania, Computer and Information Science, 1985.\\n\\nDavid Lewis.\\n\\nConvention.\\n\\nHarvard University Press, 1969.\\n\\nDiane Litman and James Allen. Recognizing and relating discourse intentions and task-oriented plans. In Cohen, Morgan and Pollack, eds. Intentions in Communication, MIT Press, 1990.\\n\\nMartha Pollack, Julia Hirschberg, and Bonnie Webber. User participation in the reasoning process of expert systems. In AAAI82, 1982.', metadata={'chunk': 11.0, 'data_source': 'Local', 'id': '759e8d2f634241fcadf1db1457aa2e88', 'page': 'None', 'source': '9503017.xml'}),\n",
       "  Document(page_content=\"Computational Linguistics 16(1):1\\n\\n\\n\\n10.\\n\\nPereira, F. C. N., and M. E. Pollack. 1991. Incremental Interpretation. Artificial Intelligence 50:37-82.\\n\\nPinkal, M. 1985. Logik und Lexikon: Die Semantik des Unbestimmten. Berlin: de Gruyter.\\n\\nPinkal, M. 1995.\\n\\nLogic and Lexicon.\\n\\nLondon: Oxford.\\n\\nPoesio, M. 1991. Relational Semantics and Scope Ambiguity. In Situation Semantics and its Applications, vol.2, ed. J. Barwise, J. M. Gawron, G. Plotkin, and S. Tutiya. Chap. 20, 469-497. Stanford, CA: CSLI.\\n\\nPoesio, M. 1994. Discourse Interpretation and the Scope of Operators. Doctoral dissertation, University of Rochester, Department of Computer Science, Rochester, NY.\\n\\nPoesio, M. 1995. A Model of Conversation Processing Based on Micro Conversational Events. In Proceedings of the Annual Meeting of the Cognitive Science Society. Pittsburgh.\\n\\nRaskin, V. 1985. Semantic Mechanisms of Humor. Dordrecht and Boston: D. Reidel.\\n\\nReiter, R. 1980. A Logic for Default Reasoning. Artificial Intelligence 13(1-2):81-132.\\n\\nReyle, U. 1993. Dealing with ambiguities by underspecification: Construction, Representation and Deduction. Journal of Semantics 3.\\n\\nRodman, R. 1976. Scope Phenomena, ``Movement Transformations,'' and Relative Clauses. In Montague Grammar, ed. Barbara Partee. 165-176. Academic Press.\", metadata={'chunk': 26.0, 'data_source': 'Local', 'id': '7decb544562a4c9ca154389bdaf08f77', 'page': 'None', 'source': '9505034.xml'}),\n",
       "  Document(page_content='These materials are © 2018 John Wiley & Sons, Inc. Any dissemination, distribution, or unauthorized use is strictly prohibited.Table of Contents\\nINTRODUCTION  ............................................................................................... 1\\nAbout This Book  ................................................................................... 1\\nFoolish Assumptions  ............................................................................ 2\\nIcons Used in This Book  ....................................................................... 2\\nCHAPTER 1:  Grasping Blockchain Fundamentals  ............................ 3\\nTracing Blockchain’s Origin  ................................................................. 3\\nThe shortcomings of current  transaction systems ..................... 4\\nThe emergence of Bitcoin  .............................................................. 5\\nThe birth of blockchain  .................................................................. 6\\nRevolutionizing the Traditional Business Network  .......................... 6\\nExploring a blockchain application  ............................................... 7\\nRecognizing the key business benefits  ......................................... 9\\nBuilding trust with blockchain  ..................................................... 10\\nCHAPTER 2:  Taking a Look at How Blockchain Works  ............... 13\\nWhy It’s Called “Blockchain”  .............................................................. 13\\nWhat Makes a Blockchain Suitable for Business?  .......................... 14\\nShared ledger  ................................................................................ 15\\nPermissions ................................................................................... 15\\nConsensus ...................................................................................... 16\\nSmart contracts ............................................................................. 17\\nIdentifying Participants and Their Roles  .......................................... 18\\nCHAPTER 3:  Propelling Business with Blockchains  ...................... 19\\nRecognizing Types of Market Friction  .............................................. 20\\nInformation frictions ..................................................................... 20\\nInteraction frictions  ...................................................................... 20\\nInnovation frictions  ....................................................................... 21\\nMoving Closer to Friction-Free Business Networks  ....................... 21\\nReducing information friction  ..................................................... 22\\nEasing interaction friction  ............................................................ 22\\nEasing innovation friction  ............................................................ 23\\nTransforming Ecosystems through Increased Visibility  ................. 24\\nTable of Contents      iii', metadata={'chunk': 0.0, 'data_source': 'Local', 'id': '3401c5b13d0141a9a6418f2e07306bf8', 'page': '3', 'source': 'Blockchain%20for%20Dummies.pdf'})]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain({\"query\": \"What is Twitter?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
